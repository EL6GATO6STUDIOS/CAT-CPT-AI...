import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlsplit, parse_qs
import random

# Sayfa baÅŸlÄ±ÄŸÄ± ve ayarlarÄ±
st.set_page_config(page_title="Cat CPT ğŸ˜º", layout="wide")
st.title("Cat CPT ğŸ˜º")

# Sohbet geÃ§miÅŸi
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# KullanÄ±cÄ±dan giriÅŸ al
text = st.text_input("Sorunuzu yazÄ±n:")

# --- YardÄ±mcÄ±lar ---

def extract_real_url(href: str) -> str:
    """
    DuckDuckGo bazÄ± sonuÃ§larÄ± /l/?uddg=... ÅŸeklinde yÃ¶nlendirir.
    Bu fonksiyon gerÃ§ek hedef URL'yi Ã§Ä±karÄ±r.
    """
    try:
        parts = urlsplit(href)
        if parts.path.startswith("/l/"):
            qs = parse_qs(parts.query)
            if "uddg" in qs and qs["uddg"]:
                return qs["uddg"][0]
        return href
    except Exception:
        return href

def ddg_search(query: str, k: int = 3):
    """
    DuckDuckGo HTML endpoint ile basit arama.
    API anahtarÄ± gerekmez.
    """
    url = "https://duckduckgo.com/html/"
    headers = {
        "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
                      "(KHTML, like Gecko) Chrome/124.0 Safari/537.36"
    }
    try:
        resp = requests.get(url, params={"q": query}, headers=headers, timeout=15)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        links = []
        for a in soup.select("a.result__a"):
            href = a.get("href", "").strip()
            if not href:
                continue
            real = extract_real_url(href)
            if real.startswith("http"):
                links.append(real)
            if len(links) >= k:
                break
        return links
    except Exception:
        return []

def fetch_first_paragraph(src_url: str) -> str | None:
    """
    Verilen sayfadan anlamlÄ± (>= 80 karakter) ilk paragrafÄ± Ã§eker.
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
                      "(KHTML, like Gecko) Chrome/124.0 Safari/537.36"
    }
    try:
        r = requests.get(src_url, headers=headers, timeout=15)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        for p in soup.find_all("p"):
            txt = (p.get_text() or "").strip()
            if len(txt) >= 80:
                return txt
        return None
    except Exception:
        return None

def generate_opinion_response(user_input: str) -> str:
    """
    Analiz/yorum cÃ¼mleleri (ÅŸablonsuz, daha doÄŸal ton; yine de Ã§eÅŸit iÃ§in kÃ¼Ã§Ã¼k bir havuz).
    """
    fikirler = [
        f"'{user_input}' konusunu deÄŸerlendirirken baÄŸlam, amaÃ§ ve etkiler birlikte dÃ¼ÅŸÃ¼nÃ¼lmeli. "
        f"Bence saÄŸlÄ±klÄ± Ã§Ä±karÄ±m, varsayÄ±mlarÄ± aÃ§Ä±k etmek ve karÅŸÄ±t gÃ¶rÃ¼ÅŸleri de tartmakla mÃ¼mkÃ¼n olur.",

        f"SorduÄŸun '{user_input}' meselesi, tek bir doÄŸru yanÄ±tÄ± olmayan, zemini baÄŸlama gÃ¶re deÄŸiÅŸen bir konu. "
        f"Ben, Ã¶lÃ§Ã¼lÃ¼ bir yaklaÅŸÄ±mÄ±n uzun vadede daha tutarlÄ± sonuÃ§ verdiÄŸini dÃ¼ÅŸÃ¼nÃ¼yorum.",

        f"'{user_input}' hakkÄ±nda net bir sonuca varmadan Ã¶nce, hem verileri hem de olasÄ± Ã¶nyargÄ±larÄ± kontrol etmek gerekir. "
        f"Bana gÃ¶re iyi bir deÄŸerlendirme; kanÄ±t, tutarlÄ±lÄ±k ve aÃ§Ä±klÄ±k Ã¼retir."
    ]
    return random.choice(fikirler)

# --- Ana akÄ±ÅŸ ---

if text:
    original_text = text
    lower_text = text.lower()

    # Analiz/yorum (gÃ¼ndelik kalÄ±plarÄ± kaldÄ±rÄ±ldÄ±; kendi cevabÄ±nÄ± Ã¼retiyor)
    if any(k in lower_text for k in ["sence", "yorumla", "analiz", "ne dÃ¼ÅŸÃ¼nÃ¼yorsun", "fikir", "gÃ¶rÃ¼ÅŸ"]):
        response = generate_opinion_response(original_text)

    else:
        # Web aramasÄ± (DuckDuckGo) + sayfadan anlamlÄ± paragraf Ã§ekme
        response = "AraÅŸtÄ±rÄ±lÄ±yor..."
        links = ddg_search(original_text, k=3)

        if not links:
            response = "ğŸ” Uygun bir sonuÃ§ bulamadÄ±m. Sorguyu biraz daha aÃ§Ä±klayabilir veya farklÄ± bir ifade deneyebilirsin."
        else:
            paragraph = None
            used_url = None
            for u in links:
                para = fetch_first_paragraph(u)
                if para:
                    paragraph = para
                    used_url = u
                    break
            if paragraph:
                # BulduÄŸu bilgiyi cÃ¼mle iÃ§inde kullan
                response = (
                    f"SorduÄŸun konuyu taradÄ±ÄŸÄ±mda Ã¶ne Ã§Ä±kan temel bilgi ÅŸu ÅŸekilde anlatÄ±lÄ±yor: {paragraph} "
                    f"(Kaynak: {used_url})"
                )
            else:
                response = f"DoÄŸrudan alÄ±ntÄ±lanabilir bir aÃ§Ä±klama bulamadÄ±m; yine de ÅŸu kaynaklara gÃ¶z atabilirsin: " + \
                           " â€¢ ".join(links)

    # Sohbet geÃ§miÅŸine ekle ve gÃ¶ster
    st.session_state.chat_history.append((original_text, response))

# Sohbet geÃ§miÅŸini sÄ±rayla gÃ¶ster
if st.session_state.chat_history:
    st.subheader("ğŸ§  Sohbet GeÃ§miÅŸi")
    for i, (q, a) in enumerate(st.session_state.chat_history, start=1):
        st.markdown(f"**{i}. Soru:** {q}")
        st.markdown(f"**{i}. Cevap:** {a}")
